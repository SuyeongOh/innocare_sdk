package com.inniopia.innocare_sdk.utils;

import android.graphics.Bitmap;
import android.media.Image;

public class ImageUtils {

    // This value is 2 ^ 18 - 1, and is used to clamp the RGB values before their ranges
    // are normalized to eight bits.
    static final int kMaxChannelValue = 262143;

    // Always prefer the native implementation if available.
    private static boolean useNativeConversion = false;

    public static Bitmap convertARGB8888ToRGB565(Bitmap bitmap){
        Bitmap convertBitmap = Bitmap.createBitmap(
                bitmap.getWidth(), bitmap.getHeight(), Bitmap.Config.RGB_565);
        for(int i = 0; i < convertBitmap.getWidth(); i++){
            for(int j = 0; j < convertBitmap.getHeight(); j++){
                int color = bitmap.getPixel(i,j);
                convertBitmap.setPixel(i, j, color);
            }
        }
        return convertBitmap;
    }
    public static Bitmap convertYUV420ToARGB8888(Image image){
        if(image == null) return null;
        Image.Plane[] planes = image.getPlanes();
        int yRowStride = planes[0].getRowStride();
        int uvRowStride = planes[1].getRowStride();
        int uvPixelStride = planes[1].getPixelStride();

        int [] bitmapPixels = new int[image.getWidth()  * image.getHeight()];
        byte[] yArray = new byte[planes[0].getBuffer().capacity()];
        byte[] uArray = new byte[planes[1].getBuffer().capacity()];
        byte[] vArray = new byte[planes[2].getBuffer().capacity()];
        planes[0].getBuffer().get(yArray);
        planes[1].getBuffer().get(uArray);
        planes[2].getBuffer().get(vArray);

        convertYUV420ToARGB8888(yArray, uArray, vArray
                ,image.getWidth(), image.getHeight()
                ,yRowStride, uvRowStride, uvPixelStride, bitmapPixels);
        return Bitmap.createBitmap(bitmapPixels, image.getWidth(), image.getHeight(), Bitmap.Config.ARGB_8888);
    }
    public static void convertYUV420ToARGB8888(
            byte[] yData,
            byte[] uData,
            byte[] vData,
            int width,
            int height,
            int yRowStride,
            int uvRowStride,
            int uvPixelStride,
            int[] out) {
        int yp = 0;
        for (int j = 0; j < height; j++) {
            int pY = yRowStride * j;
            int pUV = uvRowStride * (j >> 1);

            for (int i = 0; i < width; i++) {
                int uv_offset = pUV + (i >> 1) * uvPixelStride;

                out[yp++] = YUV2RGB(
                        0xff & yData[pY + i],
                        0xff & uData[uv_offset],
                        0xff & vData[uv_offset]);
            }
        }
    }

    private static int YUV2RGB(int y, int u, int v) {
        // Adjust and check YUV values
        y = (y - 16) < 0 ? 0 : (y - 16);
        u -= 128;
        v -= 128;

        // This is the floating point equivalent. We do the conversion in integer
        // because some Android devices do not have floating point in hardware.
        // nR = (int)(1.164 * nY + 2.018 * nU);
        // nG = (int)(1.164 * nY - 0.813 * nV - 0.391 * nU);
        // nB = (int)(1.164 * nY + 1.596 * nV);
        int y1192 = 1192 * y;
        int r = (y1192 + 1634 * v);
        int g = (y1192 - 833 * v - 400 * u);
        int b = (y1192 + 2066 * u);

        // Clipping RGB values to be inside boundaries [ 0 , kMaxChannelValue ]
        r = r > kMaxChannelValue ? kMaxChannelValue : (r < 0 ? 0 : r);
        g = g > kMaxChannelValue ? kMaxChannelValue : (g < 0 ? 0 : g);
        b = b > kMaxChannelValue ? kMaxChannelValue : (b < 0 ? 0 : b);

        return 0xff000000 | ((r << 6) & 0xff0000) | ((g >> 2) & 0xff00) | ((b >> 10) & 0xff);
    }

}
